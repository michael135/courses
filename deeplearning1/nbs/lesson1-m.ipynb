{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = \"data/dogscats/\"\n",
    "path = \"/home/ubuntu/data/dogscats/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import our class, and instantiate\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "# Grab a few images at a time for training and validation.\n",
    "# NB: They must be in subdirectories named based on their category\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 75s - loss: 0.8433 - acc: 0.7625 - val_loss: 0.0906 - val_acc: 0.9750\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size)\n",
    "\n",
    "vgg.finetune(batches)\n",
    "\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = vgg.get_batches(path+'valid', shuffle=False, batch_size=2, class_mode=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats/cat.9543.jpg',\n",
       " 'cats/cat.11290.jpg',\n",
       " 'cats/cat.77.jpg',\n",
       " 'cats/cat.6215.jpg',\n",
       " 'cats/cat.942.jpg',\n",
       " 'cats/cat.5086.jpg',\n",
       " 'cats/cat.486.jpg',\n",
       " 'cats/cat.7710.jpg',\n",
       " 'cats/cat.2323.jpg',\n",
       " 'cats/cat.5540.jpg',\n",
       " 'cats/cat.11750.jpg',\n",
       " 'cats/cat.3374.jpg',\n",
       " 'cats/cat.10296.jpg',\n",
       " 'cats/cat.8051.jpg',\n",
       " 'cats/cat.6015.jpg',\n",
       " 'cats/cat.11420.jpg',\n",
       " 'cats/cat.6261.jpg',\n",
       " 'cats/cat.9909.jpg',\n",
       " 'cats/cat.11392.jpg',\n",
       " 'cats/cat.7929.jpg',\n",
       " 'dogs/dog.3056.jpg',\n",
       " 'dogs/dog.4873.jpg',\n",
       " 'dogs/dog.9144.jpg',\n",
       " 'dogs/dog.6822.jpg',\n",
       " 'dogs/dog.11359.jpg',\n",
       " 'dogs/dog.5338.jpg',\n",
       " 'dogs/dog.6253.jpg',\n",
       " 'dogs/dog.4087.jpg',\n",
       " 'dogs/dog.2702.jpg',\n",
       " 'dogs/dog.8511.jpg',\n",
       " 'dogs/dog.9847.jpg',\n",
       " 'dogs/dog.3719.jpg',\n",
       " 'dogs/dog.6186.jpg',\n",
       " 'dogs/dog.11153.jpg',\n",
       " 'dogs/dog.2056.jpg',\n",
       " 'dogs/dog.12139.jpg',\n",
       " 'dogs/dog.10097.jpg',\n",
       " 'dogs/dog.11518.jpg',\n",
       " 'dogs/dog.7368.jpg',\n",
       " 'dogs/dog.11179.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pred = vgg.model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "[  1.2764e-03   7.0611e-05   1.8702e-03   7.0584e-02   1.2168e-02   1.0498e-03   1.5010e-02\n",
      "   2.0017e-03   2.7424e-03   8.9717e-05   1.2753e-04   5.2025e-03   4.6089e-03   1.0343e-05\n",
      "   1.3803e-04   9.3737e-01   1.4976e-02   7.1235e-04   1.2586e-03   3.9165e-02   9.8250e-01\n",
      "   9.9985e-01   9.9999e-01   6.1557e-01   9.9054e-01   9.9727e-01   9.3641e-01   1.0000e+00\n",
      "   9.9895e-01   9.9860e-01   9.9999e-01   9.8911e-01   9.9937e-01   9.9974e-01   9.9977e-01\n",
      "   9.2948e-01   9.9893e-01   9.9996e-01   9.9934e-01   9.9451e-01]\n"
     ]
    }
   ],
   "source": [
    "print (type(pred))\n",
    "print(pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/courses/deeplearning1/nbs'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category indexes are based on the ordering of categories used in the VGG model - e.g here are the first four:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the VGG model was trained in 2014, the creators subtracted the average of each of the three (R,G,B) channels first, so that the data for each channel had a mean of zero. Furthermore, their software that expected the channels to be in B,G,R order, whereas Python by default uses R,G,B. We need to preprocess our data to make these two changes, so that it is compatible with the VGG model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to define the VGG model architecture - look at how simple it is, now that we have the basic blocks defined!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pred_batch(imgs):\n",
    "    preds = model.predict(imgs)\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "\n",
    "    print('Shape: {}'.format(preds.shape))\n",
    "    print('First 5 classes: {}'.format(classes[:5]))\n",
    "    print('First 5 probabilities: {}\\n'.format(preds[0, :5]))\n",
    "    print('Predictions prob/class: ')\n",
    "    \n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        print ('  {:.4f}/{}'.format(preds[i, idx], classes[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4, 1000)\n",
      "First 5 classes: [u'tench', u'goldfish', u'great_white_shark', u'tiger_shark', u'hammerhead']\n",
      "First 5 probabilities: [  7.0631e-07   1.3811e-05   1.0875e-05   2.5794e-06   1.8271e-06]\n",
      "\n",
      "Predictions prob/class: \n",
      "  0.2156/Persian_cat\n",
      "  0.6678/tiger_cat\n",
      "  0.5281/miniature_poodle\n",
      "  0.5970/Labrador_retriever\n"
     ]
    }
   ],
   "source": [
    "pred_batch(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
