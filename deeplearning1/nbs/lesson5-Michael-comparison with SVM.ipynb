{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'data/imdb/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to look at the IMDB dataset, which contains movie reviews from IMDB, along with their sentiment. Keras comes with some helpers for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "idx = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'it', 'i']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_arr = sorted(idx, key=idx.get)\n",
    "idx_arr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the mapping from id to word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in idx.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the reviews using code copied from keras.datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the 1st review. As you see, the words have been replaced by ids. The ids can be looked up in idx2word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23022, 309, 6, 3, 1069, 209, 9, 2175, 30, 1, 169, 55, 14, 46, 82, 5869, 41, 393, 110, 138, 14, 5359, 58, 4477, 150, 8, 1, 5032, 5948, 482, 69, 5, 261, 12, 23022, 73935, 2003, 6, 73, 2436, 5, 632, 71, 6, 5359, 1, 25279, 5, 2004, 10471, 1, 5941, 1534, 34, 67, 64, 205, 140, 65, 1232, 63526, 21145, 1, 49265, 4, 1, 223, 901, 29, 3024, 69, 4, 1, 5863, 10, 694, 2, 65, 1534, 51, 10, 216, 1, 387, 8, 60, 3, 1472, 3724, 802, 5, 3521, 177, 1, 393, 10, 1238, 14030, 30, 309, 3, 353, 344, 2989, 143, 130, 5, 7804, 28, 4, 126, 5359, 1472, 2375, 5, 23022, 309, 10, 532, 12, 108, 1470, 4, 58, 556, 101, 12, 23022, 309, 6, 227, 4187, 48, 3, 2237, 12, 9, 215'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(map(str, x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first word of the first review is 23022. Let's see what that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[23022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the whole review, mapped from ids to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[o] for o in x_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are 1 for positive, 0 for negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [' '.join([idx2word[o] for o in review]) for review in x_train]\n",
    "test = [' '.join([idx2word[o] for o in review]) for review in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a c'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce vocab size by setting rare words to max index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocab_size = 5000\n",
    "\n",
    "# trn = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_train]\n",
    "# test = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell high is a car',\n",
       " 'on comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me ',\n",
       " \" believe that bromwell high's satire is much closer \",\n",
       " ' reality than is teachers the scramble ',\n",
       " \" survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried \",\n",
       " ' burn down the school i immediately recalled at high a classic line inspec',\n",
       " \"r i'm here \",\n",
       " ' sack one of your teachers student welcome ',\n",
       " \" bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].split('to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n",
      "0.1 0.84036\n",
      "0.5 0.82284\n",
      "1 0.8142\n",
      "2 0.80708\n",
      "5 0.80212\n",
      "10 0.79896\n",
      "CPU times: user 1min 14s, sys: 332 ms, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_vect = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english', \n",
    "                             ngram_range=(1, 1), analyzer='word', \n",
    "                             max_df=1.0, min_df=1, max_features=5000,\n",
    "                             binary=False)\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "print (X_train_counts.shape)\n",
    "X_test_counts = count_vect.transform(test)\n",
    "\n",
    "for c in [.01, .05, .1, .2]:\n",
    "    clf = LinearSVC(C=c, max_iter=5000)\n",
    "    clf.fit(X_train_counts, labels_train)\n",
    "\n",
    "    pred = clf.predict(X_test_counts)\n",
    "\n",
    "    print (c, accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results for 1-gram + linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 0.0005  acc =  0.86852\n",
      "c = 0.001  acc =  0.87272\n",
      "c = 0.002  acc =  0.875\n",
      "c = 0.005  acc =  0.8702\n",
      "c = 0.01  acc =  0.86676\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english', \n",
    "                             ngram_range=(1, 1), analyzer='word', \n",
    "                             max_df=1.0, min_df=1, max_features=5000,\n",
    "                             binary=False)\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "print (X_train_counts.shape)\n",
    "X_test_counts = count_vect.transform(test)\n",
    "\n",
    "for c in [0.0005, .001, .002, .005, .01]:\n",
    "    clf = LinearSVC(C=c, max_iter=5000)\n",
    "    clf.fit(X_train_counts, labels_train)\n",
    "\n",
    "    pred = clf.predict(X_test_counts)\n",
    "\n",
    "    print ('c =',c, ' acc = ', accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for 1,2-gram + linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n",
      "c = 0.001  acc =  0.87292\n",
      "c = 0.01  acc =  0.86832\n",
      "c = 0.1  acc =  0.84452\n",
      "c = 1  acc =  0.8218\n",
      "c = 10  acc =  0.80688\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english', \n",
    "                             ngram_range=(1, 2), analyzer='word', \n",
    "                             max_df=1.0, min_df=1, max_features=5000,\n",
    "                             binary=False)\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "print (X_train_counts.shape)\n",
    "X_test_counts = count_vect.transform(test)\n",
    "\n",
    "for c in [ .001, .01, .1, 1]:\n",
    "    clf = LinearSVC(C=c, max_iter=5000)\n",
    "    clf.fit(X_train_counts, labels_train)\n",
    "\n",
    "    pred = clf.predict(X_test_counts)\n",
    "\n",
    "    print ('c =',c, ' acc = ', accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000)\n",
      "c = 0.001  acc =  0.78232\n",
      "c = 0.01  acc =  0.80488\n",
      "c = 0.1  acc =  0.78404\n",
      "c = 1  acc =  0.75516\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english', \n",
    "                             ngram_range=(2, 2), analyzer='word', \n",
    "                             max_df=1.0, min_df=1, max_features=10000,\n",
    "                             binary=False)\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "print (X_train_counts.shape)\n",
    "X_test_counts = count_vect.transform(test)\n",
    "\n",
    "for c in [ .001, .01, .1, 1]:\n",
    "    clf = LinearSVC(C=c, max_iter=5000)\n",
    "    clf.fit(X_train_counts, labels_train)\n",
    "\n",
    "    pred = clf.predict(X_test_counts)\n",
    "\n",
    "    print ('c =',c, ' acc = ', accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000)\n",
      "c = 0.001  acc =  0.64868\n",
      "c = 0.01  acc =  0.68476\n",
      "c = 0.1  acc =  0.68008\n",
      "c = 1  acc =  0.66184\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english', \n",
    "                             ngram_range=(3, 3), analyzer='word', \n",
    "                             max_df=1.0, min_df=1, max_features=10000,\n",
    "                             binary=False)\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "print (X_train_counts.shape)\n",
    "X_test_counts = count_vect.transform(test)\n",
    "\n",
    "for c in [ .001, .01, .1, 1]:\n",
    "    clf = LinearSVC(C=c, max_iter=5000)\n",
    "    clf.fit(X_train_counts, labels_train)\n",
    "\n",
    "    pred = clf.predict(X_test_counts)\n",
    "\n",
    "    print ('c =',c, ' acc = ', accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
